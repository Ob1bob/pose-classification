## Primary experiments
The primary experiments build on the insights of the preliminary experiments regarding the influence of colour-focused augmentations. These experiments form the core of the study and entail the experimental augmentation of a video dataset designed for fall detection to demonstrate the feasibility of data augmentation in a real-time, pose-dependant application.

### <img src="https://user-images.githubusercontent.com/25181517/183423507-c056a6f9-1ba8-4312-a350-19bcbc5a8697.png" width="20" height="20" border="10"/> script.B1.DataGeneration.py
A video dataset that contains five different poses (sitting, standing, laying, bending, crawling), is augmented in the data generation script by superimposing joint markers onto the human silhouette. The joint locations are derived from OpenPose and are supplemented with additional information through the use of colour. The keypoint colour augmentations are applied based on either a radial or ringed colour wheel, which is notionally intended to encode spatial information based on the position of the joint. Four image datasets are generated are generated, each providing varying degrees of supplemental information to encourage class similarity among related pose samples to promote accurate classification.

<p align="center">
<img src="https://github.com/dulocian/pose-classification/blob/main/images/B1-Sample.png"/>
</p>

### <img src="https://user-images.githubusercontent.com/25181517/183423507-c056a6f9-1ba8-4312-a350-19bcbc5a8697.png" width="20" height="20" border="10"/> script.B2.VGGNetPoseClassifier.py
The structure of the CNN is inspired by the [VGGNet](https://doi.org/10.48550/arXiv.1409.1556) and is reproduced in script B2 to train and evaluate models on the image datasets generated by script B1. The VGGnet is illustrated below. The input layer of the network accepts an input image of size 156 x 108 x 4. The remainder of the network replicates the VGGNet with only its hyperparameters adjusted to favour the pose dataset.

<p align="center">
<img src="https://github.com/dulocian/pose-classification/blob/main/images/B2-VGGNet.png"/>
</p>
