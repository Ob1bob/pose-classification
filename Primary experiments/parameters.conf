; PRIMARY EXPERIMENTS CONFIG

[Global]
data_types = 0_Baseline, 1_JointColour, 2_RadialGradient, 3_RadialSegment, 4_RingGradient, 5_RingSegment
; x,y frame size that the video frames should be cropped to in data generation and read as for CNN training
x_crop = 156
y_crop = 108

[DataGen]
; Paths
video_frames_dir = ./data/1_video-frames
keypoints_dir = ./data/2_openpose-keypoints
generated_dir = ./data/3_generated-data
; x,y frame size that input video frames will be resized to and processed as
; x,y frame size that OpenPose key points were recorded in
x_axis = 160
y_axis = 120
; background colour of generated images
BG_colour = 0
; display the steps in the data generation
verbose = false
; store RGB and greyscale components separately of the RGBA data (which will display as transparency)
samples_flag = true
; store flat 1D array of 4D RGBA generated augmented images (not needed for training CNN)
CSV_flag = false
; store the generated RGBA augmented images (required for training CNN)
RGBA_flag = true

[CNN]
; Paths
generated_dir = ./data/3_generated-data/156x108
results_dir = ./data/4_CNN-training-results
batch_size = 64
epochs = 30